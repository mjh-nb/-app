# debug_main.py
import uvicorn
import json
from fastapi import FastAPI
from schemas import ClientRequest, ServerResponse, ServerResponseData
import image_processor
import llm_doctor
import data_loader

app = FastAPI()


# --- è°ƒè¯•è¾…åŠ©å‡½æ•°ï¼šè®©æ‰“å°æ›´å¥½çœ‹ ---
def print_debug_step(step_name, data):
    print(f"\n{'=' * 20} ğŸ›‘ DEBUG: {step_name} {'=' * 20}")
    try:
        # å°è¯•æŠŠ Pydantic å¯¹è±¡è½¬ä¸ºå­—å…¸
        if hasattr(data, 'dict'):
            content = data.dict()
        elif hasattr(data, 'model_dump'):  # Pydantic v2
            content = data.model_dump()
        elif hasattr(data, '__dict__'):  # æ™®é€šç±»
            content = data.__dict__
        else:
            content = data

        # æ‰“å°æ¼‚äº®çš„ JSON
        print(json.dumps(content, indent=4, ensure_ascii=False, default=str))
    except Exception as e:
        # å¦‚æœè½¬ JSON å¤±è´¥ï¼Œç›´æ¥æ‰“å°å­—ç¬¦ä¸²
        print(f"[æ— æ³•åºåˆ—åŒ–ä¸ºJSON]: {data}")
    print(f"{'=' * 50}\n")


@app.on_event("startup")
async def startup_event():
    data_loader.load_all_data()


@app.post("/api/tcm_process", response_model=ServerResponse)
async def main_entry(request: ClientRequest):
    try:
        # ==========================================
        # èŠ‚ç‚¹ 1: æ¥æ”¶åˆ° POST è¯·æ±‚
        # ==========================================
        print_debug_step("1. æ”¶åˆ°å‰ç«¯åŸå§‹è¯·æ±‚ (Request Received)", request)

        # 1. æ‹†è§£æ•°æ®
        payload = request.payload
        saved_context = payload.saved_context

        # ä¸´æ—¶å˜é‡
        current_image_features = {}

        # ==========================================
        # æ­¥éª¤ A: æ£€æŸ¥æœ‰æ²¡æœ‰å‘èˆŒå¤´ç…§ç‰‡
        # ==========================================
        if payload.images and payload.images.tongue:
            print(f"ğŸ“¸ æ£€æµ‹åˆ°èˆŒè±¡å›¾ç‰‡æ•°æ®ï¼Œæ­£åœ¨è°ƒç”¨å›¾åƒæ¨¡å‹...")
            # è°ƒç”¨ä½ çš„å›¾åƒå¤„ç†æ¨¡å—
            tongue_features = image_processor.analyze_image_features(payload.images.tongue)
            # æŠŠç»“æœå­˜å…¥ç‰¹å¾å­—å…¸
            current_image_features.update(tongue_features)
            print(f"âœ… èˆŒè±¡è¯†åˆ«å®Œæˆ: {tongue_features}")

        # ==========================================
        # æ­¥éª¤ B: æ£€æŸ¥æœ‰æ²¡æœ‰å‘é¢éƒ¨ç…§ç‰‡ (é¢„ç•™)
        # ==========================================
        if payload.images and payload.images.face:
            print("ğŸ“¸ æ”¶åˆ°é¢éƒ¨ç…§ç‰‡ï¼Œæš‚æœªå¤„ç† (ä»£ç é¢„ç•™ä½)")

        # ==========================================
        # èŠ‚ç‚¹ 2: å³å°†ä¼ é€’ç»™ LLM
        # ==========================================
        # æ„é€ ä¸€ä¸ªå­—å…¸æ¥å±•ç¤ºæˆ‘ä»¬è¦ä¼ ç»™ LLM çš„æ‰€æœ‰ä¸œè¥¿
        llm_input_debug = {
            "user_text": payload.user_text,
            "history_count": len(payload.history) if payload.history else 0,
            "history_preview": payload.history[-2:] if payload.history else [],  # åªçœ‹æœ€è¿‘2æ¡
            "saved_context": saved_context,
            "current_image_features": current_image_features
        }
        print_debug_step("2. å‡†å¤‡ä¼ ç»™ LLM Doctor çš„å‚æ•° (Input for LLM)", llm_input_debug)

        # ==========================================
        # æ­¥éª¤ C: å…¨æƒäº¤ç»™åŒ»ç”Ÿ
        # ==========================================
        doctor_result = llm_doctor.get_diagnosis_and_reply(
            user_text=payload.user_text,
            history=payload.history,
            saved_context=saved_context,
            current_image_features=current_image_features
        )

        # ==========================================
        # èŠ‚ç‚¹ 3: LLM å¤„ç†å®Œæˆ
        # ==========================================
        print_debug_step("3. LLM Doctor è¿”å›ç»“æœ (Output from LLM)", doctor_result)

        # ==========================================
        # æ­¥éª¤ D: è¿”å›
        # ==========================================
        has_new = False
        new_data = {}
        if doctor_result.new_info:
            has_new = True
            new_data = doctor_result.new_info

        response_data = ServerResponseData(
            reply_text=doctor_result.reply,
            has_new_context=has_new,
            new_context_to_save=new_data
        )

        final_response = ServerResponse(status="success", data=response_data)

        # ==========================================
        # èŠ‚ç‚¹ 4: å³å°†è¿”å›ç»™å‰ç«¯
        # ==========================================
        print_debug_step("4. æœ€ç»ˆè¿”å›ç»™å‰ç«¯çš„ JSON (Final Response)", final_response)

        return final_response

    except Exception as e:
        print(f"\nâŒ å‘ç”Ÿä¸¥é‡é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()

        empty_data = ServerResponseData(reply_text="æœåŠ¡å™¨å†…éƒ¨é”™è¯¯", has_new_context=False)
        return ServerResponse(status="error", message=str(e), data=empty_data)


if __name__ == "__main__":
    # å¯åŠ¨å‘½ä»¤
    print("ğŸš€ Debug æ¨¡å¼æœåŠ¡å™¨å¯åŠ¨ä¸­...")
    uvicorn.run("debug_main:app", host="0.0.0.0", port=8000, reload=True)